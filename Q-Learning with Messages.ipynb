{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09937f08-b3d2-4290-b15b-575b2826da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from collections import Counter\n",
    "\n",
    "np.random.seed(14)\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_to_pickle(data, filename):\n",
    "    \"\"\"\n",
    "    Save data to a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "        data (dict): Dictionary containing the data to save.\n",
    "        filename (str): Name of the file to save the data in.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    print(f\"Data successfully saved to {filename}\")\n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): Name of the file to load the data from.\n",
    "\n",
    "    Returns:\n",
    "        dict: The data loaded from the pickle file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    print(f\"Data successfully loaded from {filename}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c707ad-2a7b-40b1-86cf-70a37eb9a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities):\n",
    "    \n",
    "    \n",
    "    message_probabilities = np.array(message_probabilities) / np.sum(message_probabilities)\n",
    "    if not np.isclose(sum(message_probabilities), 1) == True:\n",
    "        raise ValueError(\"Message probabilities must sum to 1.\")\n",
    "    num_players = 2\n",
    "    num_actions = 2\n",
    "    msg_1 = [sublist[0] for sublist in messages]\n",
    "    msg_2 = [sublist[1] for sublist in messages]\n",
    "    msgs = [list(set(sublist)) for sublist in [msg_1, msg_2]]\n",
    "    msg_1, msg_2 = msgs\n",
    "    \n",
    "    \n",
    "    def choose_message(messages, probabilities):\n",
    "        index = np.random.choice(len(messages), p=probabilities)\n",
    "        return messages[index]\n",
    "    \n",
    "    choose_message(messages, message_probabilities)\n",
    "    \n",
    "    num_messages = len(messages)\n",
    "    \n",
    "    Q = [\n",
    "        {message: np.zeros(num_actions) for message in msgs[_]}\n",
    "        for _ in range(num_players)\n",
    "    ]\n",
    "    #[{'m1': array([0., 0.]), 'm2': array([0., 0.])}, Q-values foraction 0 and action 1 for message 1\n",
    "    #{'m1': array([0., 0.]), 'm2': array([0., 0.])}]\n",
    "    \n",
    "    strategies = [{message: [] for message in msgs[i]} for i in range(num_players)]\n",
    "    action_counts = [\n",
    "        {message: list(np.zeros(num_actions)) for message in msgs[i]}\n",
    "        for i in range(num_players)\n",
    "    ]\n",
    "    \n",
    "    action_history = [[] for _ in range(num_players)]\n",
    "    \n",
    "    # Compute the average correlated strategy (a distribution over joint actions)\n",
    "    action_profiles = [(0, 0), (0, 1), (1, 0), (1, 1)]  # All possible joint actions (a1, a2)\n",
    "    #correlated_strategy = {profile: 0 for profile in action_profiles}\n",
    "    \n",
    "    #2\n",
    "    for t in range(1, T + 1):\n",
    "        # Sample a message\n",
    "        \n",
    "        beta = beta0 + k*t\n",
    "        message = choose_message(messages, probabilities=message_probabilities)\n",
    "        \n",
    "        mixed_strategies = []\n",
    "        \n",
    "        # Compute mixed strategies for the selected message\n",
    "        for i in range(num_players):\n",
    "            mixed_strategy = np.exp(beta * Q[i][message[i]] - np.max(beta * Q[i][message[i]]))\n",
    "            mixed_strategy /= np.sum(mixed_strategy)\n",
    "            mixed_strategies.append(mixed_strategy)\n",
    "            \n",
    "        for i in range(num_players):\n",
    "            strategies[i][message[i]].append(mixed_strategies[i]) \n",
    "        \n",
    "        \n",
    "        actions = [np.random.choice(num_actions, p=mixed_strategies[i]) for i in range(num_players)] \n",
    "        \n",
    "        # Record actions\n",
    "        for i in range(num_players): \n",
    "            action_history[i].append(actions[i]) \n",
    "        \n",
    "        # Update action counts\n",
    "        for i in range(num_players):\n",
    "            action_counts[i][message[i]][actions[i]] += 1\n",
    "        \n",
    "        # Compute payoffs for the current actions\n",
    "        #rewards\n",
    "        #rewards = [payoffs[i][actions[i]][actions[1-i]] for i in range(num_players)]\n",
    "        \n",
    "        # Update Q-values for the selected message\n",
    "        for i in range(num_players):\n",
    "            for a in range(num_actions):\n",
    "                Q[i][message[i]][a] = (1-alpha) * Q[i][message[i]][a] + payoffs[i][a][actions[1-i]]\n",
    "\n",
    "            #Q[i][message[i]][actions[i]] = (1-alpha) * Q[i][message[i]][actions[i]] + rewards[i]\n",
    "    \n",
    "        \n",
    "    #3 \n",
    "    \n",
    "    avg_mixed_strategies = []\n",
    "    \n",
    "    left_mean_0_m1 = sum(arr[0] for arr in strategies[0]['m1'])/ len(strategies[0]['m1']) if len(strategies[0]['m1']) > 0 else 0\n",
    "    left_mean_0_m2 = sum(arr[0] for arr in strategies[0]['m2']) / len(strategies[0]['m2']) if len(strategies[0]['m2']) > 0 else 0\n",
    "    \n",
    "    right_mean_0_m1 = sum(arr[1] for arr in strategies[0]['m1']) / len(strategies[0]['m1']) if len(strategies[0]['m1']) > 0 else 0\n",
    "    right_mean_0_m2 = sum(arr[1] for arr in strategies[0]['m2']) / len(strategies[0]['m2']) if len(strategies[0]['m2']) > 0 else 0\n",
    "         \n",
    "    left_mean_1_m1 = sum(arr[0] for arr in strategies[1]['m1']) / len(strategies[1]['m1']) if len(strategies[1]['m1']) > 0 else 0\n",
    "    left_mean_1_m2 = sum(arr[0] for arr in strategies[1]['m2']) / len(strategies[1]['m2']) if len(strategies[1]['m2']) > 0 else 0\n",
    "    \n",
    "    right_mean_1_m1 = sum(arr[1] for arr in strategies[1]['m1']) / len(strategies[1]['m1']) if len(strategies[1]['m1']) > 0 else 0\n",
    "    right_mean_1_m2 = sum(arr[1] for arr in strategies[1]['m2']) / len(strategies[1]['m2']) if len(strategies[1]['m2']) > 0 else 0\n",
    "    \n",
    "    \n",
    "    avg_mixed_strategies = [{'m1': [left_mean_0_m1, right_mean_0_m1], 'm2': [left_mean_0_m2, right_mean_0_m2]}, {'m1': [left_mean_1_m1, right_mean_1_m1], 'm2': [left_mean_1_m2, right_mean_1_m2]}]\n",
    "    \n",
    "    print(avg_mixed_strategies)\n",
    "    \n",
    "    \n",
    "    expected_payoff_player0 = 0.0\n",
    "    expected_payoff_player1 = 0.0\n",
    "    \n",
    "    \n",
    "    for i, (m0, m1) in enumerate(messages):\n",
    "        prob_m = message_probabilities[i]\n",
    "        if prob_m == 0:\n",
    "            continue  # No contribution if probability is zero\n",
    "        \n",
    "        # Retrieve each player's mixed strategy for these messages\n",
    "        p0 = avg_mixed_strategies[0][m0]  # e.g. [p(0), p(1)] for player 0\n",
    "        p1 = avg_mixed_strategies[1][m1]  # e.g. [p(0), p(1)] for player 1\n",
    "    \n",
    "        # Compute conditional expected payoffs\n",
    "        # sum_{a0 in {0,1}} sum_{a1 in {0,1}} payoffs[i][a0][a1] * p0[a0] * p1[a1]\n",
    "        E0 = 0.0\n",
    "        E1 = 0.0\n",
    "        for a0 in [0, 1]:\n",
    "            for a1 in [0, 1]:\n",
    "                joint_prob = p0[a0] * p1[a1]\n",
    "                E0 += payoffs[0][a0][a1] * joint_prob\n",
    "                E1 += payoffs[1][a0][a1] * joint_prob\n",
    "        \n",
    "        # Weight by the probability of this message profile\n",
    "        expected_payoff_player0 += prob_m * E0\n",
    "        expected_payoff_player1 += prob_m * E1\n",
    "        \n",
    "    avg_social_welfare = expected_payoff_player0 + expected_payoff_player1\n",
    "\n",
    "    \n",
    "    last_iterate_strategies = [{m: strategies[i][m][-1] if len(strategies[i][m]) > 0 else [0.5, 0.5] for m in msgs[i]}  for i in range(num_players)]\n",
    "    \n",
    "\n",
    "    \n",
    "    expected_payoff_player0 = 0.0\n",
    "    expected_payoff_player1 = 0.0\n",
    "    \n",
    "    \n",
    "    for i, (m0, m1) in enumerate(messages):\n",
    "        prob_m = message_probabilities[i]\n",
    "        if prob_m == 0:\n",
    "            continue  # No contribution if probability is zero\n",
    "        \n",
    "        # Retrieve each player's mixed strategy for these messages\n",
    "        p0 = last_iterate_strategies[0][m0]  # e.g. [p(0), p(1)] for player 0\n",
    "        p1 = last_iterate_strategies[1][m1]  # e.g. [p(0), p(1)] for player 1\n",
    "    \n",
    "        # Compute conditional expected payoffs\n",
    "        # sum_{a0 in {0,1}} sum_{a1 in {0,1}} payoffs[i][a0][a1] * p0[a0] * p1[a1]\n",
    "        E0 = 0.0\n",
    "        E1 = 0.0\n",
    "        for a0 in [0, 1]:\n",
    "            for a1 in [0, 1]:\n",
    "                joint_prob = p0[a0] * p1[a1]\n",
    "                E0 += payoffs[0][a0][a1] * joint_prob\n",
    "                E1 += payoffs[1][a0][a1] * joint_prob\n",
    "        \n",
    "        # Weight by the probability of this message profile\n",
    "        expected_payoff_player0 += prob_m * E0\n",
    "        expected_payoff_player1 += prob_m * E1\n",
    "        \n",
    "    last_social_welfare = expected_payoff_player0 + expected_payoff_player1\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"last_mixed_strategy\": last_iterate_strategies,\n",
    "        \"avg_mixed_strategy\": avg_mixed_strategies,\n",
    "        \"avg_social_welfare\": avg_social_welfare,\n",
    "        \"last_social_welfare\": last_social_welfare,\n",
    "        #\"pushforward_average_strategy\": total_average_payoff,\n",
    "        #\"pushforward_last_strategy\": total_average_payoff_last,\n",
    "        \"action_history\": action_history,\n",
    "        \"strategies\": strategies\n",
    "        \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7684f-7cf3-43ac-960a-f3bdda71469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def q_plot(payoffs, T, alpha, beta0, k, messages, message_probabilities, z):\n",
    "    mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "    for j in range(10):\n",
    "        results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "        for i in range(num_players):\n",
    "            for m in ms:\n",
    "                mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "                \n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "    \n",
    "    for i in range(num_players):\n",
    "        for j, m in enumerate(ms):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Plot each of the 10 simulation time-series:\n",
    "            for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "                # sim_data is assumed shape (T, 2). \n",
    "                # We'll plot the probability of playing action 1 vs. time.\n",
    "                sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "                prob_action_0 = sim_data[:, 0]\n",
    "                ax.plot(prob_action_0,\n",
    "                        color=colors[sim_idx],\n",
    "                        alpha=0.4,\n",
    "                        linewidth=2,\n",
    "                        label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "            # Make it look nice\n",
    "            ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel(\"Time\", fontsize=12)\n",
    "            ax.set_ylabel(\"Probability of Action 0\", fontsize=12)\n",
    "            ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # If you want a single legend outside, you can do this:\n",
    "    # fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "    #            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"qlearning_results{z}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def q_plot_single(results):\n",
    "    mixed_strategy_history = [{'m1': [], 'm2': []}, {'m1': [], 'm2': []}]\n",
    "    \n",
    "    # Extract the strategies directly from the results variable\n",
    "    num_players = 2  # Assuming you have 2 players\n",
    "    ms = ['m1', 'm2']  # Messages\n",
    "\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m] = results['strategies'][i][m]\n",
    "\n",
    "    # Plotting\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "    \n",
    "    for i in range(num_players):\n",
    "        for j, m in enumerate(ms):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Extract time-series data for this player and message\n",
    "            sim_data = np.array(mixed_strategy_history[i][m])  # Now sim_data is T×2\n",
    "            if len(sim_data) > 0:  # Check to avoid errors with empty data\n",
    "                prob_action_0 = sim_data[:, 0]  # Probability of playing action 0\n",
    "                ax.plot(prob_action_0,\n",
    "                        color='blue',\n",
    "                        alpha=0.8,\n",
    "                        linewidth=2,\n",
    "                        label=f\"Player {i}, Message '{m}'\")\n",
    "\n",
    "            # Make it look nice\n",
    "            ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel(\"Time\", fontsize=12)\n",
    "            ax.set_ylabel(\"Probability of Action 0\", fontsize=12)\n",
    "            ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"qlearning_single_results.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28feac-99c9-4019-8b3c-c8f40c908fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_combinations(results_list, threshold=0.995):\n",
    "    \"\"\"\n",
    "    Count the occurrences of specific combinations of last_mixed_strategy for m1 and m2.\n",
    "    \n",
    "    Parameters:\n",
    "        results_list (list): A list of results dictionaries from the simulations.\n",
    "        threshold (float): The threshold to consider a probability as close to 1 or 0.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with combinations as keys and counts as values.\n",
    "    \"\"\"\n",
    "    def classify(probabilities, threshold):\n",
    "        \"\"\"Classify a probability vector as [1, 0] or [0, 1] if close enough.\"\"\"\n",
    "        if probabilities[0] >= threshold:\n",
    "            return \"[1, 0]\"\n",
    "        elif probabilities[1] >= threshold:\n",
    "            return \"[0, 1]\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    combination_counts = Counter()\n",
    "\n",
    "    for results in results_list:\n",
    "        # Extract the last mixed strategies\n",
    "        m1_p0 = classify(results['last_mixed_strategy'][0]['m1'], threshold)\n",
    "        m1_p1 = classify(results['last_mixed_strategy'][1]['m1'], threshold)\n",
    "        m2_p0 = classify(results['last_mixed_strategy'][0]['m2'], threshold)\n",
    "        m2_p1 = classify(results['last_mixed_strategy'][1]['m2'], threshold)\n",
    "        \n",
    "        # Store combinations of interest\n",
    "        combination_1 = (m1_p0, m1_p1)\n",
    "        combination_2 = (m1_p0, m2_p1)\n",
    "        combination_3 = (m2_p0, m1_p1)\n",
    "        \n",
    "        # Increment counts\n",
    "        combination_counts[combination_1] += 1\n",
    "        combination_counts[combination_2] += 1\n",
    "        combination_counts[combination_3] += 1\n",
    "    \n",
    "    return combination_counts\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming `results_list` is a list of dictionaries obtained from your simulations\n",
    "# results_list = [results_sim1, results_sim2, ..., results_simN]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_combinations_simple(results_list, threshold=0.995):\n",
    "    \"\"\"\n",
    "    Count occurrences of distinct patterns of the 6 results in the simulations.\n",
    "    \n",
    "    Parameters:\n",
    "        results_list (list): A list of results dictionaries from the simulations.\n",
    "        threshold (float): Threshold to classify probabilities as [1, 0] or [0, 1].\n",
    "        \n",
    "    Returns:\n",
    "        Counter: A count of all unique patterns.\n",
    "    \"\"\"\n",
    "    def classify(probabilities, threshold):\n",
    "        \"\"\"Classify probabilities as [1, 0] or [0, 1] if close to the extremes.\"\"\"\n",
    "        probabilities = np.array(probabilities)\n",
    "        if probabilities[0] >= threshold:\n",
    "            return \"[1, 0]\"\n",
    "        elif probabilities[1] >= threshold:\n",
    "            return \"[0, 1]\"\n",
    "        return \"Other\"\n",
    "\n",
    "    patterns = []\n",
    "\n",
    "    for results in results_list:\n",
    "        # Classify the three key combinations\n",
    "        combination_1 = (\n",
    "            classify(results['last_mixed_strategy'][0]['m1'], threshold),\n",
    "            classify(results['last_mixed_strategy'][1]['m1'], threshold),\n",
    "        )\n",
    "        combination_2 = (\n",
    "            classify(results['last_mixed_strategy'][0]['m1'], threshold),\n",
    "            classify(results['last_mixed_strategy'][1]['m2'], threshold),\n",
    "        )\n",
    "        combination_3 = (\n",
    "            classify(results['last_mixed_strategy'][0]['m2'], threshold),\n",
    "            classify(results['last_mixed_strategy'][1]['m1'], threshold),\n",
    "        )\n",
    "        \n",
    "        # Group all three combinations as a tuple (to handle them together)\n",
    "        patterns.append((combination_1, combination_2, combination_3))\n",
    "\n",
    "    # Count all unique patterns\n",
    "    return Counter(map(tuple, patterns))\n",
    "\n",
    "def simulate_and_count(beta0_values, k_values, T, payoffs, messages, message_probabilities, threshold=0.995):\n",
    "    correlated_eq_pattern = (\n",
    "        ('[1, 0]', '[1, 0]'),\n",
    "        ('[1, 0]', '[0, 1]'),\n",
    "        ('[0, 1]', '[1, 0]')\n",
    "    )\n",
    "    nash_eq_patterns = [\n",
    "        correlated_eq_pattern,\n",
    "        (\n",
    "            ('[0, 1]', '[1, 0]'),\n",
    "            ('[0, 1]', '[1, 0]'),\n",
    "            ('[0, 1]', '[1, 0]')\n",
    "        ),\n",
    "        (\n",
    "            ('[1, 0]', '[0, 1]'),\n",
    "            ('[1, 0]', '[0, 1]'),\n",
    "            ('[1, 0]', '[0, 1]')\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    correlated_eq_percentages = np.zeros((len(beta0_values), len(k_values)))\n",
    "    correlated_nash_percentages = np.zeros((len(beta0_values), len(k_values)))\n",
    "    \n",
    "    for i, beta0 in enumerate(beta0_values):\n",
    "        for j, k in enumerate(k_values):\n",
    "            correlated_count = 0\n",
    "            nash_count = 0\n",
    "            \n",
    "            for _ in range(100):  # 100 simulations\n",
    "                results = q_learning_2x2_game_with_pushforward(\n",
    "                    payoffs=payoffs,\n",
    "                    T=T,\n",
    "                    alpha=0,\n",
    "                    beta0=beta0,\n",
    "                    k=k,\n",
    "                    messages=messages,\n",
    "                    message_probabilities=message_probabilities\n",
    "                )\n",
    "                patterns = count_combinations_simple([results], threshold)\n",
    "                \n",
    "                # Track matched patterns to avoid double counting\n",
    "                matched_patterns = set()\n",
    "                \n",
    "                # Check correlated equilibrium\n",
    "                if correlated_eq_pattern in patterns:\n",
    "                    correlated_count += 1\n",
    "                    matched_patterns.add(correlated_eq_pattern)\n",
    "                    \n",
    "                # Check Nash equilibria\n",
    "                for pattern in nash_eq_patterns:\n",
    "                    if pattern in patterns and pattern not in matched_patterns:\n",
    "                        nash_count += 1\n",
    "                        matched_patterns.add(pattern)\n",
    "            \n",
    "            correlated_eq_percentages[i, j] = (correlated_count / 100) * 100\n",
    "            correlated_nash_percentages[i, j] = ((nash_count + correlated_count) / 100) * 100\n",
    "    \n",
    "    return correlated_eq_percentages, correlated_nash_percentages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bff97f-bcf0-4363-b4a6-454221070584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_alpha_beta(payoffs, T, messages, message_probabilities, alpha_values, beta_values, threshold=0.995):\n",
    "    \"\"\"\n",
    "    Simulate the game for varying alpha and beta with k = 0.\n",
    "    \n",
    "    Parameters:\n",
    "        payoffs (list): Payoff matrix for the 2x2 game.\n",
    "        T (int): Number of iterations for each simulation.\n",
    "        messages (list): List of messages.\n",
    "        message_probabilities (list): Probabilities for each message.\n",
    "        alpha_values (list): List of alpha values to test.\n",
    "        beta_values (list): List of beta values to test.\n",
    "        threshold (float): Threshold to classify probabilities as [1, 0] or [0, 1].\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Two heatmaps as 2D numpy arrays for correlated equilibrium and correlated/Nash equilibrium percentages.\n",
    "    \"\"\"\n",
    "    correlated_eq_pattern = (\n",
    "        ('[1, 0]', '[1, 0]'),\n",
    "        ('[1, 0]', '[0, 1]'),\n",
    "        ('[0, 1]', '[1, 0]')\n",
    "    )\n",
    "    nash_eq_patterns = [\n",
    "        correlated_eq_pattern,\n",
    "        (\n",
    "            ('[0, 1]', '[1, 0]'),\n",
    "            ('[0, 1]', '[1, 0]'),\n",
    "            ('[0, 1]', '[1, 0]')\n",
    "        ),\n",
    "        (\n",
    "            ('[1, 0]', '[0, 1]'),\n",
    "            ('[1, 0]', '[0, 1]'),\n",
    "            ('[1, 0]', '[0, 1]')\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    correlated_eq_percentages = np.zeros((len(alpha_values), len(beta_values)))\n",
    "    correlated_nash_percentages = np.zeros((len(alpha_values), len(beta_values)))\n",
    "    \n",
    "    for i, alpha in enumerate(alpha_values):\n",
    "        for j, beta in enumerate(beta_values):\n",
    "            correlated_count = 0\n",
    "            nash_count = 0\n",
    "            \n",
    "            for _ in range(100):  # 100 simulations per (alpha, beta)\n",
    "                results = q_learning_2x2_game_with_pushforward(\n",
    "                    payoffs=payoffs,\n",
    "                    T=T,\n",
    "                    alpha=alpha,\n",
    "                    beta0=beta,  # Constant beta\n",
    "                    k=0,  # No growth for beta\n",
    "                    messages=messages,\n",
    "                    message_probabilities=message_probabilities\n",
    "                )\n",
    "                patterns = count_combinations_simple([results], threshold)\n",
    "                \n",
    "                for pattern in patterns.keys():\n",
    "                    if pattern == correlated_eq_pattern:\n",
    "                        correlated_count += patterns[pattern]\n",
    "                    if pattern in nash_eq_patterns:\n",
    "                        nash_count += patterns[pattern]\n",
    "            \n",
    "            correlated_eq_percentages[i, j] = (correlated_count / 100) * 100\n",
    "            correlated_nash_percentages[i, j] = (nash_count / 100) * 100\n",
    "    \n",
    "    return correlated_eq_percentages, correlated_nash_percentages\n",
    "\n",
    "def heatmap_varying_beta0_k(payoffs, T, messages, message_probabilities, beta0_values, k_values, threshold=0.995):\n",
    "    \"\"\"\n",
    "    Generate heatmaps for correlated equilibrium and correlated/Nash equilibrium percentages\n",
    "    while varying beta0 and k.\n",
    "\n",
    "    Parameters:\n",
    "        payoffs (list): Payoff matrix for the 2x2 game.\n",
    "        T (int): Number of iterations for each simulation.\n",
    "        messages (list): List of messages.\n",
    "        message_probabilities (list): Probabilities for each message.\n",
    "        beta0_values (list): List of beta0 values to test.\n",
    "        k_values (list): List of k values to test.\n",
    "        threshold (float): Threshold to classify probabilities as [1, 0] or [0, 1].\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two heatmaps as 2D numpy arrays for correlated equilibrium and correlated/Nash equilibrium percentages.\n",
    "    \"\"\"\n",
    "    correlated_eq_percentages, correlated_nash_percentages = simulate_and_count(\n",
    "        beta0_values, k_values, T, payoffs, messages, message_probabilities, threshold\n",
    "    )\n",
    "\n",
    "    return correlated_eq_percentages, correlated_nash_percentages\n",
    "\n",
    "\n",
    "def heatmap_varying_alpha_beta(payoffs, T, messages, message_probabilities, alpha_values, beta_values, threshold=0.995):\n",
    "    \"\"\"\n",
    "    Generate heatmaps for correlated equilibrium and correlated/Nash equilibrium percentages\n",
    "    while varying alpha and beta with k = 0.\n",
    "\n",
    "    Parameters:\n",
    "        payoffs (list): Payoff matrix for the 2x2 game.\n",
    "        T (int): Number of iterations for each simulation.\n",
    "        messages (list): List of messages.\n",
    "        message_probabilities (list): Probabilities for each message.\n",
    "        alpha_values (list): List of alpha values to test.\n",
    "        beta_values (list): List of beta values to test.\n",
    "        threshold (float): Threshold to classify probabilities as [1, 0] or [0, 1].\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two heatmaps as 2D numpy arrays for correlated equilibrium and correlated/Nash equilibrium percentages.\n",
    "    \"\"\"\n",
    "    correlated_eq_percentages, correlated_nash_percentages = simulate_alpha_beta(\n",
    "        payoffs, T, messages, message_probabilities, alpha_values, beta_values, threshold\n",
    "    )\n",
    "\n",
    "    return correlated_eq_percentages, correlated_nash_percentages\n",
    "\n",
    "\n",
    "\n",
    "def plot_heatmaps(correlated_eq_percentages, correlated_nash_percentages, x_values, y_values, x_label, y_label, extra=None, filename=\"heatmaps_clean.pdf\"):\n",
    "    \"\"\"\n",
    "    Plot clean heatmaps for correlated equilibrium and correlated/Nash equilibrium percentages,\n",
    "    without any gridlines or additional marks.\n",
    "\n",
    "    Parameters:\n",
    "        correlated_eq_percentages (np.ndarray): Heatmap data for correlated equilibrium percentages.\n",
    "        correlated_nash_percentages (np.ndarray): Heatmap data for correlated/Nash equilibrium percentages.\n",
    "        x_values (list or np.ndarray): Values for the x-axis.\n",
    "        y_values (list or np.ndarray): Values for the y-axis.\n",
    "        x_label (str): Label for the x-axis.\n",
    "        y_label (str): Label for the y-axis.\n",
    "        extra (str): Extra text to add to the title.\n",
    "        filename (str): Filename to save the heatmaps.\n",
    "    \"\"\"\n",
    "    plt.style.use('seaborn-v0_8-dark')\n",
    "    extra_text = f\" ({extra})\" if extra else \"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Compute exact extent for proper axis alignment\n",
    "    x_extent = [x_values[0], x_values[-1]]\n",
    "    y_extent = [y_values[0], y_values[-1]]\n",
    "\n",
    "    # Correlated Equilibrium Heatmap\n",
    "    im1 = axes[0].imshow(correlated_eq_percentages, aspect='auto', origin='lower', \n",
    "                          extent=x_extent + y_extent, cmap='viridis')\n",
    "    axes[0].set_title(f\"Correlated Equilibrium Percentage{extra_text}\")\n",
    "    axes[0].set_xlabel(x_label)\n",
    "    axes[0].set_ylabel(y_label)\n",
    "    axes[0].tick_params(left=False, bottom=False)  # Remove ticks\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "    # Correlated Equilibrium/Nash Heatmap\n",
    "    im2 = axes[1].imshow(correlated_nash_percentages, aspect='auto', origin='lower', \n",
    "                          extent=x_extent + y_extent, cmap='plasma')\n",
    "    axes[1].set_title(f\"Correlated/Nash Equilibrium Percentage{extra_text}\")\n",
    "    axes[1].set_xlabel(x_label)\n",
    "    axes[1].set_ylabel(y_label)\n",
    "    axes[1].tick_params(left=False, bottom=False)  # Remove ticks\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    # Adjust layout and save the figure\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(filename, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    print(f\"Clean heatmaps saved to {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "payoffs = [\n",
    "    [[6, 2], [7, 0]],  # Payoffs for Player 0\n",
    "    [[6, 2], [7, 0]]   # Payoffs for Player 1\n",
    "]\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "ms = ['m1', 'm2']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a280590-27eb-4328-81c1-cc6f06630751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################################################################################\n",
    "# Prototype 1\n",
    "\n",
    "\"\"\"\n",
    "# Define a smaller test setup\n",
    "beta0_values_test = np.linspace(0, 1.0, 3)  # Reduced range for testing\n",
    "k_values_test = np.linspace(0, 1.0, 3)      # Reduced range for testing\n",
    "T_test = 30  # Reduced number of iterations for testing\n",
    "message_probabilities_test = [1/3, 1/3, 1/3, 0]  # Example message probabilities for testing\n",
    "\n",
    "# Run the smaller test for beta0 and k\n",
    "correlated_eq_test, correlated_nash_test = heatmap_varying_beta0_k(\n",
    "    payoffs=payoffs,\n",
    "    T=T_test,\n",
    "    messages=messages,\n",
    "    message_probabilities=message_probabilities_test,\n",
    "    beta0_values=beta0_values_test,\n",
    "    k_values=k_values_test\n",
    ")\n",
    "\n",
    "# Plot the results of the smaller test\n",
    "plot_heatmaps(\n",
    "    correlated_eq_test,\n",
    "    correlated_nash_test,\n",
    "    beta0_values_test,\n",
    "    k_values_test,\n",
    "    x_label=\"k (test)\",\n",
    "    y_label=\"beta0 (test)\",\n",
    "    extra=\"Test Run\",\n",
    "    filename=\"heatmaps_test.pdf\"\n",
    ")\n",
    "\"\"\"\n",
    "# Correlated Eq, same Beta\n",
    "#\"\"\"\n",
    "#T, alpha, beta0, k= 5000, 0, 1, 0\n",
    "#message_probabilities = [0.5, 0.25, 0.25, 0]\n",
    "\n",
    "message_probabilities = [1/3, 1/3, 1/3, 0]\n",
    "\n",
    "\n",
    "\n",
    "beta0_values = np.linspace(0, 1.0, 11)\n",
    "k_values = np.linspace(0, 1.0, 11)\n",
    "\"\"\"\n",
    "correlated_eq, correlated_nash = heatmap_varying_beta0_k(\n",
    "    payoffs=payoffs,  # Your payoff matrix\n",
    "    T=5000,\n",
    "    messages=messages,  # Your messages\n",
    "    message_probabilities=message_probabilities,  # Your probabilities\n",
    "    beta0_values=beta0_values,\n",
    "    k_values=k_values\n",
    ")\n",
    "save_to_pickle(correlated_eq, \"correlated_eq1.pkl\")\n",
    "save_to_pickle(correlated_nash, \"correlated_nash1.pkl\")\n",
    "\"\"\"\n",
    "correlated_eq = load_from_pickle(\"correlated_eq1.pkl\")\n",
    "correlated_nash = load_from_pickle(\"correlated_nash1.pkl\")\n",
    "\n",
    "plot_heatmaps(correlated_eq, correlated_nash, beta0_values, k_values, \"k\", \"beta0\", extra = \" [v.1]\", filename=\"heatmaps_varying_k [v.1].pdf\")\n",
    "\n",
    "\n",
    "alpha_values = np.linspace(0, 1.0, 11)\n",
    "beta_values = np.linspace(0, 1.0, 11)\n",
    "\"\"\"\n",
    "correlated_eq, correlated_nash = heatmap_varying_alpha_beta(\n",
    "    payoffs=payoffs,  # Your payoff matrix\n",
    "    T=5000,\n",
    "    messages=messages,  # Your messages\n",
    "    message_probabilities=message_probabilities,  # Your probabilities\n",
    "    alpha_values=alpha_values,\n",
    "    beta_values=beta_values\n",
    ")\n",
    "\n",
    "save_to_pickle(correlated_eq, \"correlated_eq2.pkl\")\n",
    "save_to_pickle(correlated_nash, \"correlated_nash2.pkl\")\n",
    "\"\"\"\n",
    "correlated_eq = load_from_pickle(\"correlated_eq2.pkl\")\n",
    "correlated_nash = load_from_pickle(\"correlated_nash2.pkl\")\n",
    "\n",
    "plot_heatmaps(correlated_eq, correlated_nash, beta_values, alpha_values, \"Beta\", \"Alpha\",  extra = \" [v.1]\", filename=\"heatmaps_varying_alpha [v.1].pdf\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "message_probabilities = [1/2, 1/4, 1/4, 0]\n",
    "beta0_values = np.linspace(0, 1.0, 11)\n",
    "k_values = np.linspace(0, 1.0, 11)\n",
    "\"\"\"\n",
    "correlated_eq, correlated_nash = heatmap_varying_beta0_k(\n",
    "    payoffs=payoffs,  # Your payoff matrix\n",
    "    T=5000,\n",
    "    messages=messages,  # Your messages\n",
    "    message_probabilities=message_probabilities,  # Your probabilities\n",
    "    beta0_values=beta0_values,\n",
    "    k_values=k_values\n",
    ")\n",
    "\n",
    "save_to_pickle(correlated_eq, \"correlated_eq3.pkl\")\n",
    "save_to_pickle(correlated_nash, \"correlated_nash3.pkl\")\n",
    "\"\"\"\n",
    "correlated_eq = load_from_pickle(\"correlated_eq3.pkl\")\n",
    "correlated_nash = load_from_pickle(\"correlated_nash3.pkl\")\n",
    "\n",
    "plot_heatmaps(correlated_eq, correlated_nash, beta0_values, k_values, \"k\", \"beta0\", extra = \" [v.2]\", filename = \"heatmaps_varying_k [v.2].pdf\")\n",
    "\n",
    "\n",
    "alpha_values = np.linspace(0, 1.0, 11)\n",
    "beta_values = np.linspace(0, 1.0, 11)\n",
    "\"\"\"\n",
    "correlated_eq, correlated_nash = heatmap_varying_alpha_beta(\n",
    "    payoffs=payoffs,  # Your payoff matrix\n",
    "    T=5000,\n",
    "    messages=messages,  # Your messages\n",
    "    message_probabilities=message_probabilities,  # Your probabilities\n",
    "    alpha_values=alpha_values,\n",
    "    beta_values=beta_values\n",
    ")\n",
    "\n",
    "save_to_pickle(correlated_eq, \"correlated_eq4.pkl\")\n",
    "save_to_pickle(correlated_nash, \"correlated_nash4.pkl\")\n",
    "\"\"\"\n",
    "correlated_eq = load_from_pickle(\"correlated_eq4.pkl\")\n",
    "correlated_nash = load_from_pickle(\"correlated_nash4.pkl\")\n",
    "plot_heatmaps(correlated_eq, correlated_nash, beta_values, alpha_values, \"Beta\", \"Alpha\",  extra = \" [v.2]\", filename=\"heatmaps_varying_alpha [v.2].pdf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f64960-3e13-4d94-9fd8-79c2682fbafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##\n",
    "\n",
    "\n",
    "\n",
    "alpha_values = np.linspace(0, 1.0, 11)\n",
    "beta_values = np.linspace(0, 2.0, 11)\n",
    "\n",
    "correlated_eq, correlated_nash = heatmap_varying_alpha_beta(\n",
    "    payoffs=payoffs,  # Your payoff matrix\n",
    "    T=5000,\n",
    "    messages=messages,  # Your messages\n",
    "    message_probabilities=message_probabilities,  # Your probabilities\n",
    "    alpha_values=alpha_values,\n",
    "    beta_values=beta_values\n",
    ")\n",
    "\n",
    "save_to_pickle(correlated_eq, \"correlated_eq5.pkl\")\n",
    "save_to_pickle(correlated_nash, \"correlated_nash5.pkl\")\n",
    "\n",
    "correlated_eq = load_from_pickle(\"correlated_eq5.pkl\")\n",
    "correlated_nash = load_from_pickle(\"correlated_nash5.pkl\")\n",
    "\n",
    "plot_heatmaps(correlated_eq, correlated_nash, beta_values, alpha_values, \"Beta\", \"Alpha\",  extra = \" [v.1]\", filename=\"heatmaps_varying_alpha [v.1].pdf\")\n",
    "\n",
    "\n",
    "\n",
    "########\n",
    "#Do these!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "results_list = []\n",
    "\n",
    "\n",
    "start = time()\n",
    "for i in range(100):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    results_list.append(results)\n",
    "end = time()\n",
    "time_difference = end - start\n",
    "print(f\"Time difference is {time_difference}\")\n",
    "    \n",
    "    \n",
    "pattern_counts = count_combinations_simple(results_list)\n",
    "\n",
    "for pattern, count in pattern_counts.items():\n",
    "    print(f\"Pattern {pattern}: {count}\")\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "results_list = []\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0, 0.5, 0\n",
    "#message_probabilities = [0.5, 0.25, 0.25, 0]\n",
    "\n",
    "message_probabilities = [1/3, 1/3, 1/3, 0]\n",
    "\n",
    "\n",
    "start = time()\n",
    "for i in range(100):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    results_list.append(results)\n",
    "end = time()\n",
    "time_difference = end - start\n",
    "print(f\"Time difference is {time_difference}\")\n",
    "    \n",
    "    \n",
    "pattern_counts = count_combinations_simple(results_list)\n",
    "\n",
    "for pattern, count in pattern_counts.items():\n",
    "    print(f\"Pattern {pattern}: {count}\")\n",
    "    \n",
    "###################\n",
    "T, alpha, beta0, k= 5000, 0, 0.5, 0\n",
    "\n",
    "\n",
    "message_probabilities = [1/3, 1/3, 1/3, 0]\n",
    "q_plot(payoffs, T, alpha, beta0, k, messages, message_probabilities, 10)\n",
    "\n",
    "z = 10\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "plt.style.use('seaborn-v0_8-dark')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            prob_action_0 = sim_data[:, 0]\n",
    "            ax.plot(prob_action_0,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 0\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"qlearning_results{z}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "################################\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0, 0.5, 0\n",
    "results_list = []\n",
    "\n",
    "for z in range(500):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    if (\n",
    "        np.array_equal(results['last_mixed_strategy'][0]['m1'], np.array([1., 0.])) and\n",
    "        np.array_equal(results['last_mixed_strategy'][1]['m1'], np.array([1., 0.])) and\n",
    "        np.array_equal(results['last_mixed_strategy'][0]['m1'], np.array([1., 0.])) and\n",
    "        np.array_equal(results['last_mixed_strategy'][1]['m2'], np.array([0., 1.])) and\n",
    "        np.array_equal(results['last_mixed_strategy'][0]['m2'], np.array([0., 1.])) and\n",
    "        np.array_equal(results['last_mixed_strategy'][1]['m1'], np.array([1., 0.]))\n",
    "    ):\n",
    "        structured_result = [\n",
    "            {\n",
    "                \"m1\": results['strategies'][0]['m1'],  # Convert to list for JSON compatibility\n",
    "                \"m2\": results['strategies'][0]['m2']\n",
    "            },\n",
    "            {\n",
    "                \"m1\": results['strategies'][1]['m1'],\n",
    "                \"m2\": results['strategies'][1]['m2']\n",
    "            }\n",
    "        ]\n",
    "        results_list.append(structured_result)\n",
    "\n",
    "\n",
    "results_list \n",
    "\n",
    "\n",
    "\n",
    "def q_plot_from_results(results_list, T):\n",
    "    \"\"\"\n",
    "    Plot the mixed strategy histories from the given results_list.\n",
    "\n",
    "    Parameters:\n",
    "    results_list (list): A list of structured results containing strategies.\n",
    "    T (int): Number of time steps.\n",
    "    \"\"\"\n",
    "    mixed_strategy_history = [{'m1': [], 'm2': []}, {'m1': [], 'm2': []}]\n",
    "\n",
    "    # Process results_list to extract mixed strategies\n",
    "    for results in results_list:\n",
    "        for i in range(2):  # Two players\n",
    "            for m in ['m1', 'm2']:\n",
    "                mixed_strategy_history[i][m].append(results[i][m])\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(results_list)))\n",
    "\n",
    "    for i in range(2):  # Players\n",
    "        for j, m in enumerate(['m1', 'm2']):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Plot each simulation time-series:\n",
    "            for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "                # sim_data is assumed shape (T, 2). We'll plot the probability of action 0 vs. time.\n",
    "                sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "                prob_action_0 = sim_data[:, 0]\n",
    "                ax.plot(prob_action_0,\n",
    "                        color=colors[sim_idx],\n",
    "                        alpha=0.6,\n",
    "                        linewidth=2,\n",
    "                        label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "            # Make it look nice\n",
    "            ax.set_title(f\"Player {i+1}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel(\"Time\", fontsize=12)\n",
    "            ax.set_ylabel(\"Probability of Action 0\", fontsize=12)\n",
    "            ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"qlearning_results.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming results_list contains the first 10 structured results\n",
    "q_plot_from_results(results_list, T)\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27304d26-c9b5-4e17-baf5-4b0fc0513843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_social_welfare(avg_mixed_strategy, payoffs, message_probabilities, messages):\n",
    "    \"\"\"\n",
    "    Compute social welfare (utilitarian aggregation) using average mixed strategies.\n",
    "\n",
    "    Parameters:\n",
    "        avg_mixed_strategy (list): Average mixed strategies for both players.\n",
    "        payoffs (list): Payoff matrices for both players.\n",
    "        message_probabilities (list): Probabilities for each message.\n",
    "        messages (list): List of message pairs.\n",
    "\n",
    "    Returns:\n",
    "        float: Computed social welfare.\n",
    "    \"\"\"\n",
    "    social_welfare = 0.0\n",
    "\n",
    "    for i, (m0, m1) in enumerate(messages):\n",
    "        prob_m = message_probabilities[i]\n",
    "        if prob_m == 0:\n",
    "            continue  # Skip messages with zero probability\n",
    "\n",
    "        # Retrieve each player's mixed strategy for these messages\n",
    "        p0 = avg_mixed_strategy[0][m0]  # e.g., [p(0), p(1)] for player 0\n",
    "        p1 = avg_mixed_strategy[1][m1]  # e.g., [p(0), p(1)] for player 1\n",
    "\n",
    "        # Compute expected social welfare for this message profile\n",
    "        for a0 in range(len(p0)):\n",
    "            for a1 in range(len(p1)):\n",
    "                joint_prob = p0[a0] * p1[a1]\n",
    "                social_welfare += prob_m * joint_prob * (payoffs[0][a0][a1] + payoffs[1][a0][a1])\n",
    "\n",
    "    return social_welfare\n",
    "\n",
    "def heatmap_social_welfare_alpha_beta(payoffs, T, alpha_values, beta_values, messages, message_probabilities):\n",
    "    \"\"\"\n",
    "    Generate a heatmap for social welfare over varying alpha and beta values.\n",
    "\n",
    "    Parameters:\n",
    "        payoffs (list): Payoff matrices for both players.\n",
    "        T (int): Number of iterations.\n",
    "        alpha_values (list): Values for alpha.\n",
    "        beta_values (list): Values for beta.\n",
    "        messages (list): List of message pairs.\n",
    "        message_probabilities (list): Probabilities for each message.\n",
    "    \"\"\"\n",
    "    welfare_matrix = np.zeros((len(alpha_values), len(beta_values)))\n",
    "\n",
    "    for i, alpha in enumerate(alpha_values):\n",
    "        for j, beta in enumerate(beta_values):\n",
    "            # Run the simulation\n",
    "            results = q_learning_2x2_game_with_pushforward(\n",
    "                payoffs, T, alpha, beta, 0, messages, message_probabilities\n",
    "            )\n",
    "\n",
    "            # Compute social welfare using avg_mixed_strategy\n",
    "            social_welfare = compute_social_welfare(\n",
    "                results['avg_mixed_strategy'], payoffs, message_probabilities, messages\n",
    "            )\n",
    "            welfare_matrix[i, j] = social_welfare\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(welfare_matrix, origin='lower', aspect='auto', cmap='viridis',\n",
    "               extent=[beta_values[0], beta_values[-1], alpha_values[0], alpha_values[-1]])\n",
    "    plt.colorbar(label=\"Social Welfare\")\n",
    "    plt.title(\"Social Welfare Heatmap (Alpha vs. Beta)\", fontsize=16)\n",
    "    plt.xlabel(\"Beta\", fontsize=14)\n",
    "    plt.ylabel(\"Alpha\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"social_welfare_heatmap_alpha_beta.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def heatmap_social_welfare_beta0_k(payoffs, T, beta0_values, k_values, messages, message_probabilities):\n",
    "    \"\"\"\n",
    "    Generate a heatmap for social welfare over varying beta0 and k values.\n",
    "\n",
    "    Parameters:\n",
    "        payoffs (list): Payoff matrices for both players.\n",
    "        T (int): Number of iterations.\n",
    "        beta0_values (list): Values for beta0.\n",
    "        k_values (list): Values for k.\n",
    "        messages (list): List of message pairs.\n",
    "        message_probabilities (list): Probabilities for each message.\n",
    "    \"\"\"\n",
    "    welfare_matrix = np.zeros((len(beta0_values), len(k_values)))\n",
    "\n",
    "    for i, beta0 in enumerate(beta0_values):\n",
    "        for j, k in enumerate(k_values):\n",
    "            # Run the simulation\n",
    "            results = q_learning_2x2_game_with_pushforward(\n",
    "                payoffs, T, 0, beta0, k, messages, message_probabilities\n",
    "            )\n",
    "\n",
    "            # Compute social welfare using avg_mixed_strategy\n",
    "            social_welfare = compute_social_welfare(\n",
    "                results['avg_mixed_strategy'], payoffs, message_probabilities, messages\n",
    "            )\n",
    "            welfare_matrix[i, j] = social_welfare\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(welfare_matrix, origin='lower', aspect='auto', cmap='plasma',\n",
    "               extent=[k_values[0], k_values[-1], beta0_values[0], beta0_values[-1]])\n",
    "    plt.colorbar(label=\"Social Welfare\")\n",
    "    plt.title(\"Social Welfare Heatmap (Beta0 vs. k)\", fontsize=16)\n",
    "    plt.xlabel(\"k\", fontsize=14)\n",
    "    plt.ylabel(\"Beta0\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"social_welfare_heatmap_beta0_k.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Parameters for simulation\n",
    "alpha_values = np.linspace(0, 1.0, 11)\n",
    "beta_values = np.linspace(0, 1.0, 11)\n",
    "beta0_values = np.linspace(0, 1.0, 11)\n",
    "k_values = np.linspace(0, 0.01, 11)\n",
    "\n",
    "# Generate and plot the heatmaps\n",
    "heatmap_social_welfare_alpha_beta(\n",
    "    payoffs=payoffs,\n",
    "    T=5000,\n",
    "    alpha_values=alpha_values,\n",
    "    beta_values=beta_values,\n",
    "    messages=messages,\n",
    "    message_probabilities=[1/3, 1/3, 1/3, 0]\n",
    ")\n",
    "\n",
    "heatmap_social_welfare_beta0_k(\n",
    "    payoffs=payoffs,\n",
    "    T=5000,\n",
    "    beta0_values=beta0_values,\n",
    "    k_values=k_values,\n",
    "    messages=messages,\n",
    "    message_probabilities=[1/3, 1/3, 1/3, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a8994-aac7-41a3-bb2e-79f69457d62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
