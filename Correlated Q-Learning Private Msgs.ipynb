{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb52ba9-9c0d-454c-a1bf-ad2b3d88e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9737182-5cb6-4947-af6c-e84531504374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities):\n",
    "    message_probabilities = np.array(message_probabilities) / np.sum(message_probabilities)\n",
    "    if sum(message_probabilities) != 1:\n",
    "        raise ValueError(\"Message probabilities must sum to 1.\")\n",
    "    num_players = 2\n",
    "    num_actions = 2\n",
    "    msg_1 = [sublist[0] for sublist in messages]\n",
    "    msg_2 = [sublist[1] for sublist in messages]\n",
    "    msgs = [list(set(sublist)) for sublist in [msg_1, msg_2]]\n",
    "    msg_1, msg_2 = msgs\n",
    "    #msg_1 is the messages that player 0 can see\n",
    "    \n",
    "    def choose_message(messages, probabilities):\n",
    "        index = np.random.choice(len(messages), p=probabilities)\n",
    "        return messages[index]\n",
    "    \n",
    "    choose_message(messages, message_probabilities)\n",
    "    \n",
    "    num_messages = len(messages)\n",
    "    \n",
    "    Q = [\n",
    "        {message: np.zeros(num_actions) for message in msgs[_]}\n",
    "        for _ in range(num_players)\n",
    "    ]\n",
    "    \n",
    "    strategies = [{message: [] for message in msgs[i]} for i in range(num_players)]\n",
    "    action_counts = [\n",
    "        {message: list(np.zeros(num_actions)) for message in msgs[i]}\n",
    "        for i in range(num_players)\n",
    "    ]\n",
    "    \n",
    "    action_history = [[] for _ in range(num_players)]\n",
    "    \n",
    "    # Compute the average correlated strategy (a distribution over joint actions)\n",
    "    action_profiles = [(0, 0), (0, 1), (1, 0), (1, 1)]  # All possible joint actions (a1, a2)\n",
    "    #correlated_strategy = {profile: 0 for profile in action_profiles}\n",
    "    \n",
    "    #2\n",
    "    for t in range(1, T + 1):\n",
    "        # Sample a message\n",
    "        \n",
    "        beta = beta0 + k*t\n",
    "        message = choose_message(messages, probabilities=message_probabilities)\n",
    "        \n",
    "        mixed_strategies = []\n",
    "        \n",
    "        # Compute mixed strategies for the selected message\n",
    "        for i in range(num_players):\n",
    "            mixed_strategy = np.exp(beta * Q[i][message[i]] - np.max(beta * Q[i][message[i]]))\n",
    "            mixed_strategy /= np.sum(mixed_strategy)\n",
    "            mixed_strategies.append(mixed_strategy)\n",
    "            \n",
    "        for i in range(num_players):\n",
    "            strategies[i][message[i]].append(mixed_strategies[i]) \n",
    "        \n",
    "        \n",
    "        actions = [np.random.choice(num_actions, p=mixed_strategies[i]) for i in range(num_players)] \n",
    "        \n",
    "        # Record actions\n",
    "        for i in range(num_players): \n",
    "            action_history[i].append(actions[i]) \n",
    "        \n",
    "        # Update action counts\n",
    "        for i in range(num_players):\n",
    "            action_counts[i][message[i]][actions[i]] += 1\n",
    "        \n",
    "        # Compute payoffs for the current actions\n",
    "        rewards = [payoffs[i][actions[i]][actions[1-i]] for i in range(num_players)]\n",
    "        rewards_counterf = [payoffs[i][1-actions[i]][actions[1-i]] for i in range(num_players)]\n",
    "\n",
    "        # Update Q-values for the selected message\n",
    "        for i in range(num_players):\n",
    "            Q[i][message[i]][actions[i]] = (1-alpha) * Q[i][message[i]][actions[i]] + rewards[i]\n",
    " \n",
    "        \n",
    "    #3 \n",
    "    \n",
    "    avg_mixed_strategies = []\n",
    "    \n",
    "    left_mean_0_m1 = sum(arr[0] for arr in strategies[0]['m1'])/ len(strategies[0]['m1']) if len(strategies[0]['m1']) > 0 else 0\n",
    "    left_mean_0_m2 = sum(arr[0] for arr in strategies[0]['m2']) / len(strategies[0]['m2']) if len(strategies[0]['m2']) > 0 else 0\n",
    "    \n",
    "    right_mean_0_m1 = sum(arr[1] for arr in strategies[0]['m1']) / len(strategies[0]['m1']) if len(strategies[0]['m1']) > 0 else 0\n",
    "    right_mean_0_m2 = sum(arr[1] for arr in strategies[0]['m2']) / len(strategies[0]['m2']) if len(strategies[0]['m2']) > 0 else 0\n",
    "         \n",
    "    left_mean_1_m1 = sum(arr[0] for arr in strategies[1]['m1']) / len(strategies[1]['m1']) if len(strategies[1]['m1']) > 0 else 0\n",
    "    left_mean_1_m2 = sum(arr[0] for arr in strategies[1]['m2']) / len(strategies[1]['m2']) if len(strategies[1]['m2']) > 0 else 0\n",
    "    \n",
    "    right_mean_1_m1 = sum(arr[1] for arr in strategies[1]['m1']) / len(strategies[1]['m1']) if len(strategies[1]['m1']) > 0 else 0\n",
    "    right_mean_1_m2 = sum(arr[1] for arr in strategies[1]['m2']) / len(strategies[1]['m2']) if len(strategies[1]['m2']) > 0 else 0\n",
    "    \n",
    "    \n",
    "    avg_mixed_strategies = [{'m1': [left_mean_0_m1, right_mean_0_m1], 'm2': [left_mean_0_m2, right_mean_0_m2]}, {'m1': [left_mean_1_m1, right_mean_1_m1], 'm2': [left_mean_1_m2, right_mean_1_m2]}]\n",
    "    \n",
    "    print(avg_mixed_strategies)\n",
    "    \n",
    "    \n",
    "    expected_payoff_player0 = 0.0\n",
    "    expected_payoff_player1 = 0.0\n",
    "    \n",
    "    \n",
    "    for i, (m0, m1) in enumerate(messages):\n",
    "        prob_m = message_probabilities[i]\n",
    "        if prob_m == 0:\n",
    "            continue  # No contribution if probability is zero\n",
    "        \n",
    "        # Retrieve each player's mixed strategy for these messages\n",
    "        p0 = avg_mixed_strategies[0][m0]  # e.g. [p(0), p(1)] for player 0\n",
    "        p1 = avg_mixed_strategies[1][m1]  # e.g. [p(0), p(1)] for player 1\n",
    "    \n",
    "        # Compute conditional expected payoffs\n",
    "        # sum_{a0 in {0,1}} sum_{a1 in {0,1}} payoffs[i][a0][a1] * p0[a0] * p1[a1]\n",
    "        E0 = 0.0\n",
    "        E1 = 0.0\n",
    "        for a0 in [0, 1]:\n",
    "            for a1 in [0, 1]:\n",
    "                joint_prob = p0[a0] * p1[a1]\n",
    "                E0 += payoffs[0][a0][a1] * joint_prob\n",
    "                E1 += payoffs[1][a0][a1] * joint_prob\n",
    "        \n",
    "        # Weight by the probability of this message profile\n",
    "        expected_payoff_player0 += prob_m * E0\n",
    "        expected_payoff_player1 += prob_m * E1\n",
    "        \n",
    "    avg_social_welfare = expected_payoff_player0 + expected_payoff_player1\n",
    "\n",
    "    \n",
    "    last_iterate_strategies = [{m: strategies[i][m][-1] if len(strategies[i][m]) > 0 else [0.5, 0.5] for m in msgs[i]}  for i in range(num_players)]\n",
    "    \n",
    "\n",
    "    \n",
    "    expected_payoff_player0 = 0.0\n",
    "    expected_payoff_player1 = 0.0\n",
    "    \n",
    "    \n",
    "    for i, (m0, m1) in enumerate(messages):\n",
    "        prob_m = message_probabilities[i]\n",
    "        if prob_m == 0:\n",
    "            continue  # No contribution if probability is zero\n",
    "        \n",
    "        # Retrieve each player's mixed strategy for these messages\n",
    "        p0 = last_iterate_strategies[0][m0]  # e.g. [p(0), p(1)] for player 0\n",
    "        p1 = last_iterate_strategies[1][m1]  # e.g. [p(0), p(1)] for player 1\n",
    "    \n",
    "        # Compute conditional expected payoffs\n",
    "        # sum_{a0 in {0,1}} sum_{a1 in {0,1}} payoffs[i][a0][a1] * p0[a0] * p1[a1]\n",
    "        E0 = 0.0\n",
    "        E1 = 0.0\n",
    "        for a0 in [0, 1]:\n",
    "            for a1 in [0, 1]:\n",
    "                joint_prob = p0[a0] * p1[a1]\n",
    "                E0 += payoffs[0][a0][a1] * joint_prob\n",
    "                E1 += payoffs[1][a0][a1] * joint_prob\n",
    "        \n",
    "        # Weight by the probability of this message profile\n",
    "        expected_payoff_player0 += prob_m * E0\n",
    "        expected_payoff_player1 += prob_m * E1\n",
    "        \n",
    "    last_social_welfare = expected_payoff_player0 + expected_payoff_player1\n",
    "    \n",
    "    return {\n",
    "        \"last_iterate\": last_iterate_strategies,\n",
    "        \"avg_mixed_strategy\": avg_mixed_strategies,\n",
    "        \"avg_social_welfare\": avg_social_welfare,\n",
    "        \"last_social_welfare\": last_social_welfare,\n",
    "        #\"pushforward_average_strategy\": total_average_payoff,\n",
    "        #\"pushforward_last_strategy\": total_average_payoff_last,\n",
    "        \"action_history\": action_history,\n",
    "        \"strategies\": strategies\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a56344-f266-457c-85c1-c9af23ec552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 1\n",
    "\n",
    "\n",
    "# Correlated Eq, same Beta\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.7, 0\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [0.5, 0.25, 0.25, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results1.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016dee7b-e938-482b-98c8-4cd1e4027c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 2\n",
    "\n",
    "\n",
    "# Correlated Eq, increasing beta\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.1, 0.01\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [0.5, 0.25, 0.25, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results2.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e01182-80b5-4e3a-a93f-d6c8a4cb4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 3\n",
    "\n",
    "\n",
    "# Correlated Eq, same Beta, different message probabilities\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.7, 0\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [1/3, 1/3, 1/3, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results3.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b62b9-e3dc-4239-8915-99d650c59482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 4\n",
    "\n",
    "# Correlated Eq, increasing Beta, different message probabilities\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.1, 0.001\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [1/3, 1/3, 1/3, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results4.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79ac9e-7396-4a4b-b7e6-b261d91cc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 5\n",
    "\n",
    "# NOT Correlated Eq, same Beta\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.7, 0\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [1, 0, 0, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            if sim_data.shape[0] == 0:  # Check if sim_data is empty\n",
    "                print(f\"Skipping Simulation {sim_idx} due to empty data.\")\n",
    "                continue  # Skip this simulation\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results5.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fed87-cc0a-46fc-902f-a19523790519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 6\n",
    "\n",
    "# NOT Correlated Eq, increasing beta\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.1, 0.001\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [1, 0, 0, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            if sim_data.shape[0] == 0:  # Check if sim_data is empty\n",
    "                print(f\"Skipping Simulation {sim_idx} due to empty data.\")\n",
    "                continue  # Skip this simulation\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results6.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fa091-5e53-458c-af51-5777f59a0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 7\n",
    "# NOT Correlated Eq, increasing beta, higher initial beta\n",
    "\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.7, 0.01\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [1, 0, 0, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            if sim_data.shape[0] == 0:  # Check if sim_data is empty\n",
    "                print(f\"Skipping Simulation {sim_idx} due to empty data.\")\n",
    "                continue  # Skip this simulation\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results7.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d96d7e-8035-491a-851e-d0ab1903abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype 8\n",
    "T, alpha, beta0, k= 5000, 0.5, 0.1, 0.01\n",
    "messages = [['m1', 'm1'], ['m1', 'm2'], ['m2', 'm1'], ['m2', 'm2']]\n",
    "\n",
    "ms = ['m1', 'm2']\n",
    "message_probabilities = [1, 0, 0, 0]\n",
    "\n",
    "num_players = 2\n",
    "num_actions = 2\n",
    "#results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta, messages, message_probabilities)\n",
    "\n",
    "mixed_strategy_history = [{'m1': [], 'm2': []},{'m1': [], 'm2': []}]\n",
    "\n",
    "for j in range(10):\n",
    "    results = q_learning_2x2_game_with_pushforward(payoffs, T, alpha, beta0, k, messages, message_probabilities)\n",
    "    for i in range(num_players):\n",
    "        for m in ms:\n",
    "            mixed_strategy_history[i][m].append(results['strategies'][i][m])\n",
    "            \n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(num_players):\n",
    "    for j, m in enumerate(ms):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Plot each of the 10 simulation time-series:\n",
    "        for sim_idx, sim_data in enumerate(mixed_strategy_history[i][m]):\n",
    "            # sim_data is assumed shape (T, 2). \n",
    "            # We'll plot the probability of playing action 1 vs. time.\n",
    "            sim_data = np.array(sim_data)  # Now sim_data is T×2\n",
    "            if sim_data.shape[0] == 0:  # Check if sim_data is empty\n",
    "                print(f\"Skipping Simulation {sim_idx} due to empty data.\")\n",
    "                continue  # Skip this simulation\n",
    "            prob_action_1 = sim_data[:, 1]\n",
    "            ax.plot(prob_action_1,\n",
    "                    color=colors[sim_idx],\n",
    "                    alpha=0.4,\n",
    "                    linewidth=2,\n",
    "                    label=f\"Simulation {sim_idx+1}\" if sim_idx == 0 else None)\n",
    "\n",
    "        # Make it look nice\n",
    "        ax.set_title(f\"Player {i}, Message '{m}'\", fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time\", fontsize=12)\n",
    "        ax.set_ylabel(\"Probability of Action 1\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Probabilities should be between 0 and 1\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# If you want a single legend outside, you can do this:\n",
    "# fig.legend(*axes[0,0].get_legend_handles_labels(), loc=\"upper center\",\n",
    "#            bbox_to_anchor=(0.5, 1.05), ncol=5, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"qlearning_results8.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
